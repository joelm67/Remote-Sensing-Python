{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of biophysical_variables.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joelm67/Remote-Sensing-Python/blob/main/Copy_of_biophysical_variables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWH8K3bcg1CR"
      },
      "source": [
        "# Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igHBZUzHhHhz"
      },
      "source": [
        "The goal of this notebook is to demonstrate how to estimate biophysical variables from remote sensing.  The biophysical variables of interest include Leaf Area Index (LAI), fraction of Photosynthetically Active Radiation (fPAR), biomass, yield to name a few. As you may remember from previous classes, there are a number of different ways to get at these *continuous* variables.  In this notebook we will use regression and machine learning algorithms in regression mode to achive our goal.  The general steps are:\n",
        "- acquire location specific biophysical variable measurements (e.g. LAI)\n",
        "- acquire satellite reflectance data over the same location/time period\n",
        "- build a regression model that explains the relationship between spectral reflectance and the biophysical variable\n",
        "- apply the model to the reflectance image to produce a biopysical variable *map*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66YPQuRAiW5O"
      },
      "source": [
        "For this assignment, we are going to use MODIS LAI/fPAR product to extract LAI data at 500-meter spatial resolution.  We will then extract the Sentinel-2 MSI reflectance data that have been downscaled to 500-meter spatial resolution.  We will then build a relationship between MSI spectral bands and LAI and apply the regression model to a 10-meter MSI image to make a LAI map.  For your convenience, I used the following Google Earth Engine code to extract the LAI and MSI reflectance samples into a CSV file that we will work with: \n",
        "[GEE code](https://code.earthengine.google.com/c68270f84af46205122aab17ff8f1880?noload=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoCCoEM8YgY9"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQiuxR0gYnu5"
      },
      "source": [
        "Lets start by importing appropriate libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krg0OsngYWLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6688ffb3-2672-42ec-f8b8-d067f957b6c5"
      },
      "source": [
        "#!add-apt-repository ppa:ubuntugis/ppa\n",
        "#!apt update\n",
        "#!apt install gdal-bin libgdal-dev\n",
        "!pip3 install rasterio\n",
        "\n",
        "import rasterio\n",
        "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "from pandas import Series, DataFrame, Panel\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rasterio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/a8/63d45bb74c17c60e607b4beae77d68ad4c9ea6dff788534ce8c835d1d2f1/rasterio-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (19.1MB)\n",
            "\u001b[K     |████████████████████████████████| 19.1MB 1.3MB/s \n",
            "\u001b[?25hCollecting affine\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/a6/1a39a1ede71210e3ddaf623982b06ecfc5c5c03741ae659073159184cd3e/affine-2.3.0-py2.py3-none-any.whl\n",
            "Collecting click-plugins\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from rasterio) (20.3.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/42/1e/947eadf10d6804bf276eb8a038bd5307996dceaaa41cfd21b7a15ec62f5d/cligj-0.7.1-py3-none-any.whl\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from rasterio) (2020.12.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rasterio) (1.19.5)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from rasterio) (7.1.2)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/0e/d27d6e806d6c0d1a2cfdc5d1f088e42339a0a54a09c3343f7f81ec8947ea/snuggs-1.4.7-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from snuggs>=1.4.1->rasterio) (2.4.7)\n",
            "Installing collected packages: affine, click-plugins, cligj, snuggs, rasterio\n",
            "Successfully installed affine-2.3.0 click-plugins-1.1.1 cligj-0.7.1 rasterio-1.2.0 snuggs-1.4.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uza5IZV-ZAzO"
      },
      "source": [
        "# Grab data and explore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LLMLAo8ZE62"
      },
      "source": [
        "Lets grab a a single pixel time series data first.  It is contained in a comma separated file to be imported from a cloud location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIcGxAwpZ7eh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c776fd-58de-45a8-c029-1d62b76dd484"
      },
      "source": [
        "# read the csv file into a pandas series object\n",
        "# header=0 tells pandas that the first row of the csv file contains the column headers\n",
        "# squeeze=True means we only have one data column and that we are interested in a Series and not a DataFrame.\n",
        "laiData = read_csv('https://storage.googleapis.com/alexi_daily/EnvSt956/s2_lai_rand.csv', header=0, squeeze=True)\n",
        "\n",
        "# It is often easier to perform manipulations of your time series data in a \n",
        "# DataFrame rather than a Series object and you can easily convert your \n",
        "# loaded Series to a DataFrame as follows\n",
        "df = pd.DataFrame(laiData)\n",
        "\n",
        "# lets explore the dataset\n",
        "# peek at the data\n",
        "print(df.head(10))\n",
        "\n",
        "# Descriptive statistics\n",
        "print(df.describe())\n",
        "\n",
        "# let's add a few additional features\n",
        "df['SR'] = df['nir']/df['red']\n",
        "df['NDVI'] = (df['nir'] - df['red'])/(df['nir'] + df['red'])\n",
        "\n",
        "# Descriptive statistics\n",
        "print(df.describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   rand  blue  green   red   nir  swir1  swir2  LAI\n",
            "0     1   664    814   878  2041   2393   1740   12\n",
            "1     3   138    188   102  1066    504    277   23\n",
            "2    12   251    462   217  5130   1883    822   29\n",
            "3    14   265    527   274  4670   1816    801   43\n",
            "4    21   380    586   416  3313   1843    930   17\n",
            "5    24  1116   1450  1799  3301   4154   2918    4\n",
            "6    31   326    590   393  4570   2266   1070   34\n",
            "7    36   328    524   361  3535   2186   1171   22\n",
            "8    40   432    649   478  4281   2008   1039   26\n",
            "9    43   309    708   299  3769   1908    934   51\n",
            "               rand          blue  ...         swir2           LAI\n",
            "count  16932.000000  16932.000000  ...  16932.000000  16932.000000\n",
            "mean   50030.296008    582.200035  ...   1637.589712     16.517777\n",
            "std    28776.371810    554.804054  ...    797.850504     15.813860\n",
            "min        1.000000      2.000000  ...     23.000000      1.000000\n",
            "25%    25093.750000    327.000000  ...   1004.000000      4.000000\n",
            "50%    49912.500000    460.000000  ...   1430.500000     10.000000\n",
            "75%    74725.750000    708.000000  ...   2146.000000     25.000000\n",
            "max    99986.000000   9506.000000  ...   5236.000000     70.000000\n",
            "\n",
            "[8 rows x 8 columns]\n",
            "               rand          blue  ...            SR          NDVI\n",
            "count  16932.000000  16932.000000  ...  16932.000000  16932.000000\n",
            "mean   50030.296008    582.200035  ...      5.965962      0.519573\n",
            "std    28776.371810    554.804054  ...      5.949682      0.267276\n",
            "min        1.000000      2.000000  ...      0.405607     -0.422872\n",
            "25%    25093.750000    327.000000  ...      1.682647      0.254468\n",
            "50%    49912.500000    460.000000  ...      2.946467      0.493218\n",
            "75%    74725.750000    708.000000  ...      8.654757      0.792848\n",
            "max    99986.000000   9506.000000  ...     40.289474      0.951562\n",
            "\n",
            "[8 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loE_HR6BmVPW"
      },
      "source": [
        "Now lets build a relationship between MSI reflectance and LAI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeVIsStTnfq2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "outputId": "9ddf77ed-f715-4496-a00e-1a520da384da"
      },
      "source": [
        "# Import function to create training and test set splits\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Import function to automatically create polynomial features! \n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "# Import Linear Regression and a regularized regression function\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LassoCV\n",
        "# Finally, import function to make a machine learning pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "df['X'] = df['SR']\n",
        "df['y'] = df['LAI']\n",
        "\n",
        "# Alpha (regularization strength) of LASSO regression\n",
        "lasso_eps = 0.0001\n",
        "lasso_nalpha=20\n",
        "lasso_iter=5000\n",
        "# Min and max degree of polynomials features to consider\n",
        "degree_min = 2\n",
        "degree_max = 8\n",
        "# Test/train split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['X'], df['y'],test_size=0.3)\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Make a pipeline model with polynomial transformation and LASSO regression with cross-validation, run it for increasing degree of polynomial (complexity of the model)\n",
        "for degree in range(degree_min,degree_max+1):\n",
        "    model = make_pipeline(PolynomialFeatures(degree, interaction_only=False), LassoCV(eps=lasso_eps,n_alphas=lasso_nalpha,max_iter=lasso_iter,\n",
        "                                                                                      normalize=True,cv=5))\n",
        "    model.fit(X_train,y_train)\n",
        "    test_pred = np.array(model.predict(X_test))\n",
        "    RMSE=np.sqrt(np.sum(np.square(test_pred-y_test)))\n",
        "    test_score = model.score(X_test,y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8757     19.782427\n",
            "6172      2.089080\n",
            "9588      1.861230\n",
            "1645      9.394089\n",
            "9114      9.633721\n",
            "           ...    \n",
            "15892     1.902639\n",
            "6850      1.442645\n",
            "5214      2.394811\n",
            "7952      3.687500\n",
            "11370     2.020436\n",
            "Name: X, Length: 11852, dtype: float64\n",
            "8757     42\n",
            "6172      3\n",
            "9588      5\n",
            "1645     36\n",
            "9114     36\n",
            "         ..\n",
            "15892     2\n",
            "6850      2\n",
            "5214     18\n",
            "7952      6\n",
            "11370     4\n",
            "Name: y, Length: 11852, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-297b83875021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     model = make_pipeline(PolynomialFeatures(degree, interaction_only=False), LassoCV(eps=lasso_eps,n_alphas=lasso_nalpha,max_iter=lasso_iter,\n\u001b[1;32m     34\u001b[0m                                                                                       normalize=True,cv=5))\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mRMSE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \"\"\"\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \"\"\"\n\u001b[0;32m-> 1508\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m         combinations = self._combinations(n_features, self.degree,\n\u001b[1;32m   1510\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[19.78242678  2.08908046  1.86123033 ...  2.39481066  3.6875\n  2.02043597].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCeEtzNggdmX"
      },
      "source": [
        "Now lets do image form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwMopL-7gpno"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP4yaW3DghiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54555991-c922-4832-d386-b48dc742ec5f"
      },
      "source": [
        "# read the spring image\n",
        "!wget https://storage.googleapis.com/alexi_daily/EnvSt956/grassland_ndvi_1990-2020.tif grassland_ndvi_1990-2020.tif\n",
        "tsimage = rasterio.open('grassland_ndvi_1990-2020.tif')\n",
        "tsarr = tsimage.read()\n",
        "[bands,rows,cols] = tsarr.shape\n",
        "print(bands)\n",
        "print(rows)\n",
        "print(cols)\n",
        "#tsarr = reshape_as_image(tsarr) # reshape my numpy array from <bands><rows><cols> to <rows><cols><bands>\n",
        "\n",
        "dates = read_csv('https://storage.googleapis.com/alexi_daily/EnvSt956/grassland_ndvi_bandnames.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
        "\n",
        "#print(dates)\n",
        "\n",
        "tsarr = tsarr.reshape(bands,rows*cols) # collapse 3D array into a 2D array\n",
        "df = pd.DataFrame(tsarr, index=dates)\n",
        "\n",
        "print(df)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-25 23:06:52--  https://storage.googleapis.com/alexi_daily/EnvSt956/grassland_ndvi_1990-2020.tif\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.219.128, 142.250.125.128, 74.125.124.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.219.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 132273858 (126M) [image/tiff]\n",
            "Saving to: ‘grassland_ndvi_1990-2020.tif.1’\n",
            "\n",
            "grassland_ndvi_1990 100%[===================>] 126.15M   225MB/s    in 0.6s    \n",
            "\n",
            "2021-01-25 23:06:53 (225 MB/s) - ‘grassland_ndvi_1990-2020.tif.1’ saved [132273858/132273858]\n",
            "\n",
            "--2021-01-25 23:06:53--  http://grassland_ndvi_1990-2020.tif/\n",
            "Resolving grassland_ndvi_1990-2020.tif (grassland_ndvi_1990-2020.tif)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘grassland_ndvi_1990-2020.tif’\n",
            "FINISHED --2021-01-25 23:06:53--\n",
            "Total wall clock time: 0.8s\n",
            "Downloaded: 1 files, 126M in 0.6s (225 MB/s)\n",
            "2755\n",
            "207\n",
            "218\n",
            "                             0      1      2      ...  45123  45124  45125\n",
            "(1990, 3, 28, LT05, 32035)       0      0      0  ...      0      0      0\n",
            "(1990, 4, 6, LT05, 31035)        0      0      0  ...      0      0      0\n",
            "(1990, 4, 13, LT05, 32035)       0      0      0  ...      0      0      0\n",
            "(1990, 4, 22, LT05, 31035)       0      0      0  ...      0      0      0\n",
            "(1990, 4, 22, LT05, 31036)       0      0      0  ...      0      0      0\n",
            "...                            ...    ...    ...  ...    ...    ...    ...\n",
            "(2019, 12, 18, LC08, 31035)      0      0      0  ...      0      0      0\n",
            "(2019, 12, 18, LC08, 31036)      0      0      0  ...      0      0      0\n",
            "(2019, 12, 25, LC08, 32035)      0      0      0  ...      0      0      0\n",
            "(2019, 12, 26, LE07, 31035)      0      0      0  ...      0      0      0\n",
            "(2019, 12, 26, LE07, 31036)      0      0      0  ...      0      0      0\n",
            "\n",
            "[2755 rows x 45126 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhNAlJaltISo"
      },
      "source": [
        "# Fit Linear Trend and get coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEieQdfetQs8"
      },
      "source": [
        "bbbb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbamDib8tRrx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "eb5a16d7-2ca6-4fdb-ee04-e9272610e03f"
      },
      "source": [
        "coefficients, residuals, _, _, _ = np.polyfit(range(len(annual.index)),annual,1,full=True)\n",
        "mse = residuals[0]/(len(annual.index))\n",
        "nrmse = np.sqrt(mse)/(annual.max() - annual.min())\n",
        "print('Slope ' + str(coefficients[0]))\n",
        "print('NRMSE: ' + str(nrmse))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6ade4198a5bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcoefficients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresiduals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mannual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresiduals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mannual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Slope '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NRMSE: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'annual' is not defined"
          ]
        }
      ]
    }
  ]
}